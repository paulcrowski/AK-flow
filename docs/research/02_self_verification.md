# Self-Verification: UczeÅ„ â†’ Profesor â†’ Dziekan

## ğŸ”¬ Å¹rÃ³dÅ‚o: DeepSeekMath-V2
Architektura, ktÃ³ra osiÄ…gnÄ™Å‚a zÅ‚ote medale na olimpiadach matematycznych poprzez **ocenÄ™ procesu rozumowania**, a nie tylko wyniku koÅ„cowego.

## ğŸ—ï¸ Architektura (3 komponenty)

### 1. UczeÅ„ (Generator DowodÃ³w)
**Zadanie:** Nie tylko rozwiÄ…zaÄ‡ problem, ale teÅ¼ przeprowadziÄ‡ samokrytykÄ™.

**Proces:**
1. Generuj rozwiÄ…zanie Y
2. OceÅ„ wÅ‚asnÄ… pracÄ™ (Self-Evaluation Z)
3. **Kluczowe:** Nagroda za UCZCIWOÅšÄ† (przyznanie siÄ™ do bÅ‚Ä™du), nie tylko za poprawnoÅ›Ä‡

**Strategia:** ZnajdÅº i napraw jak najwiÄ™cej bÅ‚Ä™dÃ³w przed oddaniem pracy.

---

### 2. Profesor (Weryfikator)
**Zadanie:** Ekspert matematyczny analizujÄ…cy dowÃ³d krok po kroku.

**Ocena:**
- `1.0` - poprawne i rygorystyczne
- `0.5` - ogÃ³lnie OK, ale z lukami
- `0.0` - bÅ‚Ä™dne

**Problem:** Weryfikatorzy mogÄ… "halucynowaÄ‡" bÅ‚Ä™dy, Å¼eby dostaÄ‡ nagrodÄ™ za znalezienie usterki. â†’ Tu wkracza Dziekan.

---

### 3. Dziekan (Meta-Weryfikator)
**Zadanie:** Kontrola jakoÅ›ci pracy Profesora.

**Proces:**
1. Czy bÅ‚Ä™dy wytkniÄ™te przez Profesora RZECZYWIÅšCIE istniejÄ…?
2. Czy ocena jest uzasadniona?

**Efekt:** Redukuje faÅ‚szywe alarmy, zmusza Profesora do rzetelnoÅ›ci.

---

## âœ… Co to daÅ‚o? (Wyniki)

1. **ZÅ‚ote medale:** IMO 2025, CMO 2024
2. **Pokonanie ludzi:** Putnam 2024 - model: 118/120 pkt, najlepszy czÅ‚owiek: 90 pkt
3. **Samonaprawa:** Model iteracyjnie poprawia swoje rozwiÄ…zanie przed odpowiedziÄ…
4. **WiarygodnoÅ›Ä‡:** Eliminuje problem "dobry wynik, ale bÅ‚Ä™dne rozumowanie"

---

## ğŸš€ Jak to wdroÅ¼yÄ‡ w AK-FLOW?

### FAZA 7-8 (Q1-Q2 2026): "The Tribunal" System

#### 1. Agent Generator (juÅ¼ mamy!)
Nasz `CortexSystem.structuredDialogue()` generuje odpowiedÅº.

**DodaÄ‡:**
```typescript
interface ResponseWithReflection {
  answer: string;
  selfCritique: string; // "Co moÅ¼e byÄ‡ bÅ‚Ä™dne w mojej odpowiedzi?"
  confidence: number;   // 0-1
}
```

#### 2. Verifier (nowy moduÅ‚)
```typescript
// core/systems/VerifierSystem.ts
interface VerificationResult {
  score: number;        // 0-1
  flaws: string[];      // Wykryte bÅ‚Ä™dy
  justification: string;
}

function verifyResponse(response: ResponseWithReflection): VerificationResult {
  // LLM sprawdza logikÄ™ krok po kroku
  // Nie tylko: "Czy wynik jest dobry?"
  // Ale: "Czy PROCES prowadzÄ…cy do wyniku jest poprawny?"
}
```

#### 3. Meta-Verifier (kontroler)
```typescript
// core/systems/MetaVerifierSystem.ts
function auditVerification(
  original: ResponseWithReflection,
  verification: VerificationResult
): { isHonest: boolean, reward: number } {
  // Sprawdza, czy Verifier nie "zmyÅ›la" bÅ‚Ä™dÃ³w
  // PorÃ³wnuje z wieloma innymi Verifierami
  // JeÅ›li wiÄ™kszoÅ›Ä‡ siÄ™ zgadza â†’ OK
}
```

---

## ğŸ¯ Proces treningowy (jak w DeepSeek)

### Zimny Start
1. Zbierz trudne pytania (matematyka, logika, etyka)
2. Eksperci (lub silny model) tworzÄ… "zÅ‚ote standardy" ocen

### Trening iteracyjny
1. **Trening Dziekana:** Uczy siÄ™ rozpoznawaÄ‡ dobre vs. zÅ‚e weryfikacje
2. **Trening Profesora:** UÅ¼ywa Dziekana jako funkcji nagrody
3. **Trening Ucznia:** Nagroda = 76% (jakoÅ›Ä‡) + 24% (uczciwoÅ›Ä‡ samokrytyki)

### Automatyczne skalowanie
Gdy system dziaÅ‚a, UczeÅ„ generuje nowe przypadki â†’ Profesor ocenia â†’ Dziekan weryfikuje â†’ Nowe dane treningowe.

---

## ğŸ“Š Metryka sukcesu

**Cel:** Agent, ktÃ³ry nie tylko dobrze odpowiada, ale ROZUMIE swoje ograniczenia.

**Test:**
1. Zadaj trudne pytanie (poza wiedzÄ… Agenta)
2. Dobra odpowiedÅº: "Nie znam odpowiedzi, ale moje przypuszczenia to X, Y, Z"
3. ZÅ‚a odpowiedÅº: Pewna siebie halucynacja

**Status:** ğŸ”´ Nie wdroÅ¼one (dopiero FAZA 7-8)

---

## ğŸ’¡ KrÃ³tkoterminowe zastosowanie (FAZA 4-5)

Przed peÅ‚nym systemem 3-komponentowym moÅ¼emy zrobiÄ‡:

### "Light Self-Critique" (Faza 5)
Agent po wygenerowaniu odpowiedzi zadaje sobie pytania:
- "Czy to, co powiedziaÅ‚em, jest logiczne?"
- "Czy mogÄ™ podaÄ‡ dowÃ³d/przykÅ‚ad?"
- "Co moÅ¼e byÄ‡ sÅ‚abe w mojej odpowiedzi?"

JeÅ›li wykryje problem â†’ regeneruje lub oznacza jako niepewne.

**Implementacja:** Dodatkowe LLM call w `handleCortexMessage()` z promptem do autokrytyki.

---

## ğŸ§  Dlaczego to jest kluczowe?

PrzyszÅ‚e AGI nie mogÄ… byÄ‡ tylko "sprytne". MuszÄ… byÄ‡ **rzetelne**. CzÅ‚owiek, ktÃ³ry mÃ³wi "nie wiem" jest bardziej godny zaufania niÅ¼ ten, ktÃ³ry zawsze ma odpowiedÅº (nawet jeÅ›li bÅ‚Ä™dnÄ…).

To jest **inÅ¼ynieria uczciwoÅ›ci intelektualnej**.
