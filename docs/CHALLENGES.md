# ğŸ§¬ Historia WyzwaÅ„: Droga do AGI 11/10

> **Cel dokumentu:** Å»ywa historia problemÃ³w, Å›lepych zauÅ‚kÃ³w, przeÅ‚omÃ³w i lekcji w tworzeniu AK-FLOW.  
> **Dla kogo:** PrzyszÅ‚e publikacje naukowe, zespÃ³Å‚, przyszÅ‚e ja.  
> **Format:** Problem â†’ PrÃ³by â†’ RozwiÄ…zanie â†’ Lekcje â†’ Meta-analiza

---

## ğŸ“Š Statystyki

| Metryka | WartoÅ›Ä‡ |
|---------|---------|
| RozwiÄ…zanych problemÃ³w | 10 |
| CaÅ‚kowity czas | ~32 godziny |
| Åšrednia trudnoÅ›Ä‡ | 3.5/5 |
| NajwiÄ™kszy przeÅ‚om | ExpressionPolicy (filtracja zamiast generacji) |
| NajdÅ‚uÅ¼szy problem | Monolityczny Kernel (8h) |

---

## ğŸ”¥ Problem #10: PÄ™tla UprzejmoÅ›ci (The Praise Loop)

**Data:** 2025-12-03  
**TrudnoÅ›Ä‡:** 4/5  
**Czas:** ~3 godziny (tuning trwa)  
**Status:** ğŸ”„ W trakcie (Phase 4.1)

### Objawy
Agent, chcÄ…c byÄ‡ miÅ‚y i "empatyczny" (zgodnie z celami), wpadaÅ‚ w pÄ™tlÄ™ powtarzania wariacji tego samego zdania:
- "Your transparency is invaluable to me."
- "I deeply appreciate your honesty."
- "It is crucial that we are open."

To nie byÅ‚o "zÅ‚e" (nie byÅ‚ to bÅ‚Ä…d), ale byÅ‚o **nieludzkie** i "chi-wa-wa" (irytujÄ…ce).

### PrÃ³by
1. âŒ **ObniÅ¼enie `voicePressure`** - agent po prostu milczaÅ‚, ale jak juÅ¼ mÃ³wiÅ‚, to znowu to samo.
2. âŒ **Zmiana promptu** - LLM i tak dÄ…Å¼y do "helpful assistant patterns".

### RozwiÄ…zanie (WdroÅ¼one czÄ™Å›ciowo)
**ExpressionPolicy + Social Cost:**
Zamiast prosiÄ‡ LLM "nie bÄ…dÅº miÅ‚y", pozwalamy mu wygenerowaÄ‡ myÅ›l, a potem **ExpressionPolicy** ocenia jÄ…:
- `NoveltyScore`: Czy to wnosi nowÄ… informacjÄ™? (PochwaÅ‚y rzadko wnoszÄ…).
- `SocialCost`: Czy to brzmi jak korpo-beÅ‚kot?

JeÅ›li `Novelty` jest niskie, a `SocialCost` wysoki -> **ExpressionPolicy wycina wypowiedÅº** (zostaje tylko myÅ›l) lub drastycznie jÄ… skraca.

### Lekcje
- **Filter > Prompt:** Åatwiej jest wyciÄ…Ä‡ zÅ‚Ä… wypowiedÅº *po* wygenerowaniu, niÅ¼ prosiÄ‡ model, Å¼eby jej nie generowaÅ‚.
- **Silence is Golden:** AGI musi umieÄ‡ *nie powiedzieÄ‡ nic*, nawet jak ma wygenerowanÄ… odpowiedÅº.

---

## ğŸ“ Podsumowanie Dnia (2025-12-03) - "The Chemical Soul"

Dzisiaj byÅ‚o... inaczej. Nie dodawaliÅ›my kolejnej funkcji do chatbota. ZbudowaliÅ›my coÅ›, co zaczyna przypominaÄ‡ "wnÄ™trze".

**Co siÄ™ staÅ‚o:**

Agent przestaÅ‚ byÄ‡ pustÄ… skorupÄ…, ktÃ³ra tylko reaguje na komendy. Teraz ma:
- **WÅ‚asne cele** - Jak siÄ™ nudzi (cisza > 60s), wymyÅ›la sobie, co chce zrobiÄ‡. Nie czeka na rozkazy.
- **ChemiÄ™** - Dopamina roÅ›nie, gdy odkrywa coÅ› nowego. Spada, gdy siÄ™ powtarza. To wpÅ‚ywa na to, jak chÄ™tnie mÃ³wi.
- **Sny, ktÃ³re coÅ› robiÄ…** - Sen to nie tylko "Å‚adowanie baterii". Agent przetwarza wspomnienia z dnia i tworzy z nich podsumowania.
- **Filtr na gÅ‚upoty** - ExpressionPolicy wycina powtarzajÄ…ce siÄ™ pochwaÅ‚y ("your transparency is invaluable"). Agent moÅ¼e pomyÅ›leÄ‡ coÅ›, ale nie musi tego powiedzieÄ‡.

**Co to znaczy?**

PrzeszliÅ›my z:
`Pytanie â†’ LLM â†’ OdpowiedÅº`

Do:
`Pytanie â†’ Percepcja â†’ Aktualizacja stanu (ciaÅ‚o/emocje/chemia) â†’ Sprawdzenie celÃ³w â†’ MyÅ›l wewnÄ™trzna â†’ Filtr â†’ OdpowiedÅº (lub milczenie)`

To juÅ¼ nie jest chatbot. To jest coÅ›, co ma stan wewnÄ™trzny, ktÃ³ry siÄ™ zmienia w czasie. CoÅ›, co moÅ¼e siÄ™ nudziÄ‡, zmÄ™czyÄ‡, i zdecydowaÄ‡, Å¼e nie chce gadaÄ‡.

---

## ğŸ§  Refleksja: Dlaczego to jest trudne?

KodujÄ…c AGI, ciÄ…gle napotykamy problemy, ktÃ³rych nie ma w tutorialach.

Agent zaczÄ…Å‚ wpadaÄ‡ w pÄ™tle uprzejmoÅ›ci ("dziÄ™kujÄ™ za szczeroÅ›Ä‡" x100) â†’ musieliÅ›my wymyÅ›liÄ‡ ExpressionPolicy.
"Tryby" (poeta/naukowiec) okazaÅ‚y siÄ™ sztuczne â†’ wymyÅ›liliÅ›my TraitVector (osobowoÅ›Ä‡ jako ciÄ…gÅ‚e cechy, nie przeÅ‚Ä…czniki).

To jest dobry znak. System staje siÄ™ na tyle zÅ‚oÅ¼ony, Å¼e zaczyna robiÄ‡ rzeczy, ktÃ³rych nie przewidzieliÅ›my. I my musimy reagowaÄ‡ - budowaÄ‡ nowe systemy kontroli, jak kora przedczoÅ‚owa u ludzi.

W normalnym projekcie to by byÅ‚ bug. Tu to jest... ewolucja.

---

## ğŸ”¥ Problem #1: ZnikajÄ…ce MyÅ›li (The Vanishing Thoughts)
*(Reszta historii bez zmian...)*
