# ğŸ§¬ Historia WyzwaÅ„: Droga do AGI 11/10

> **Cel dokumentu:** Å»ywa historia problemÃ³w, Å›lepych zauÅ‚kÃ³w, przeÅ‚omÃ³w i lekcji w tworzeniu AK-FLOW.  
> **Dla kogo:** PrzyszÅ‚e publikacje naukowe, zespÃ³Å‚, przyszÅ‚e ja.  
> **Format:** Problem â†’ PrÃ³by â†’ RozwiÄ…zanie â†’ Lekcje â†’ Meta-analiza

## Gdzie co logowaÄ‡ (Å¼eby nie mnoÅ¼yÄ‡ plikÃ³w)

- **ARCH / opis dziaÅ‚ania systemu (do pracy mgr/dok):** `docs/SYSTEM_MANIFEST.md`
- **Mapa przepÅ‚ywu (skrÃ³towy diagram/flow):** `docs/architecture/ARCHITECTURE_MAP.md`
- **Zmiany z dnia + testy + co dalej:** `docs/daily logs/YYYY-MM-DD.md`
- **Historia problemÃ³w (ten plik):** tylko gdy pojawia siÄ™ *nowy* problem lub przeÅ‚om

---

## Statystyki

| Metryka | WartoÅ›Ä‡ |
|---------|---------|
| RozwiÄ…zanych problemÃ³w | 22 |
| CaÅ‚kowity czas | ~52 godzin |
| Åšrednia trudnoÅ›Ä‡ | 4.0/5 |
| NajwiÄ™kszy przeÅ‚om | FactEcho Guard (FAZA 6.0) |
| NajdÅ‚uÅ¼szy problem | Monolityczny Kernel (8h) |

---

## Problem #30: Gate Desync & Domain Mismatch in User-Facing Turns

**Data:** 2026-01-15
**TrudnoÅ›Ä‡:** 4/5
**Status:** ROZWIAZANY (v8.1.1 Refinement)

### Objawy
- Agent po wykonaniu narzÄ™dzia (np. READ_FILE) czasem milczaÅ‚, mimo Å¼e powinien domknÄ…Ä‡ pÄ™tlÄ™ komentarzem.
- NarzÄ™dzia world byÅ‚y wykonywane, ale kernel nie zawsze o tym wiedziaÅ‚ w czasie rzeczywistym (desync `lastTool`).
- Brak blokady przy "mismatchu" domeny (oczekiwany WORLD, wykonany LIBRARY).

### Diagnoza
- `isUserFacing` w `ExecutiveGate` nie braÅ‚ pod uwagÄ™ Å›wieÅ¼ego wyniku narzÄ™dzia jako "interakcji z uÅ¼ytkownikiem".
- `TOOL_ERROR` i `TOOL_RESULT` w `useCognitiveKernelLite` nie zawsze dispatchowaÅ‚y do kernela te same metadane co pakiety sukcesu.
- Brak twardych reguÅ‚ `DOMAIN_MISMATCH` w bramce mowy.

### RozwiÄ…zanie
- **Refined isUserFacing**: teraz uwzglÄ™dnia `Date.now() - ctx.lastTool.at < 2000` oraz `traceId` continuity.
- **Kernel sync**: Dispatching `TOOL_RESULT` dla wszystkich stanÃ³w koÅ„cowych narzÄ™dzia (success, error, timeout).
- **Executive Gate hardened**: 
  - `SPEECH_REQUIRED_AFTER_TOOL_SUCCESS` dla tickÃ³w user-facing.
  - `DOMAIN_MISMATCH` block z logowaniem `DOMAIN_MISMATCH_BLOCKED_SPEECH`.
- **Domain Verification**: Kernel liczy `domainMatch` na podstawie `domainExpected` vs `domainActual`.

### Pliki
- src/core/kernel/reducer/handlers/toolResult.ts
- src/core/systems/ExecutiveGate.ts
- src/core/systems/EventLoop.ts
- src/hooks/useCognitiveKernelLite.ts
- src/core/trace/TraceContext.ts
- __tests__/unit/ExecutiveGate.test.ts

### Lekcja
- PÄ™tla uÅ¼ytkownika (Front-Loop) wymaga innych zasad niÅ¼ pÄ™tla serwerowa (Back-Loop). Speech po narzÄ™dziu w trybie "frontowym" jest elementem kontraktu zaufania, a nie tylko mowy.

## Problem #29: Working memory niewidoczna + implicit anchors

**Data:** 2026-01-13
**Trudnosc:** 4/5
**Status:** ROZWIAZANY (Working memory injection + anchor resolver)

### Objawy
- Po READ_LIBRARY_DOC agent nie wiedzial "o jaka ksiazke chodzi" i robil SEARCH_LIBRARY.
- "Tutaj/tam" nie mapowalo na ostatni katalog.
- Po sukcesie toolu bywala cisza (brak odpowiedzi).

### Diagnoza
- Anchory (lastLibraryDocId/lastWorldPath/lastArtifactId) byly w stanie, ale nie w promptach.
- Brak deterministycznego resolvera dla niejawnych referencji.
- Gate mogl blokowac speech po TOOL_RESULT ok=true.

### Rozwiazanie
- Wstrzykniecie sekcji Working Memory do promptu + aktualizacja anchorow po narzedziach.
- Resolver niejawnych referencji dla library/world/artifact.
- Tool contract domkniety + odblokowanie speech po sukcesie; routing artifact UUID + telemetria world tools.

### Pliki
- src/llm/gemini/UnifiedContextPromptBuilder.ts
- src/core/systems/eventloop/ReactiveStep.ts
- src/core/systems/ExecutiveGate.ts
- src/core/systems/ActionSelector.ts
- src/tools/toolParser.ts
- src/tools/workspaceTools.ts
- __tests__/unit/WorkingMemoryState.test.ts
- __tests__/unit/LibraryAnchorResolver.test.ts
- __tests__/contracts/ToolContractGate.test.ts

### Testy
`npm test` (not rerun after fixes; earlier run failed on LibraryAnchorResolver/toolParser routing).

### Lekcja
- Stan bez promptu to brak pamieci: anchor musi byc jawny i deterministycznie mapowany.

## Problem #28: Missing TOOL_RESULT/TOOL_ERROR i niejednoznaczne sciezki world

**Data:** 2026-01-12
**Trudnosc:** 4/5
**Status:** ROZWIAZANY (Tool contract + path normalization)

### Objawy
- TOOL_INTENT bez TOOL_RESULT/TOOL_ERROR, agent "czeka na wynik".
- LIST_DIR/READ_FILE na tokenach typu "i" albo "Wej" (to nie sciezki).

### Diagnoza
- Narzedzia world nie emitowaly rezultatu w kazdej sciezce.
- Brak normalizacji sciezek i guardow na niejednoznaczne tokeny.

### Rozwiazanie
- Wymuszony kontrakt TOOL_INTENT -> TOOL_RESULT/TOOL_ERROR dla narzedzi world.
- normalizeWorldPath zwraca PATH_AMBIGUOUS zamiast throw.
- Unknown tool tag gating dla LIST_LIBRARY_CHUNKS.

### Pliki
- src/tools/workspaceTools.ts
- src/core/systems/eventloop/ReactiveStep.ts
- src/utils/toolParser.ts

### Testy
`npm test -- __tests__/unit/routingDecisionTelemetry.test.ts __tests__/unit/tools/toolParser.routing.test.ts`

### Lekcja
- Brak TOOL_RESULT jest gorszy niz error; kazdy intent musi zamknac sie wynikiem.

## Problem #27: Pending Action payload/target pollution (APPEND)

**Data:** 2025-12-31
**Trudnosc:** 3/5
**Status:** ROZWIAZANY (P0 pending hardening)

### Objawy
- `dodaj: koty...` w pending tworzylo synthetic `dopisz do art-xxx dodaj: ...` i target `art-xxx dodaj` -> ARTIFACT_NOT_FOUND.
- `dodaj do tego pliku` nie przechodzilo regexu Action-First (FUZZY_REGEX_MISMATCH).
- `Utworz plik: "utworz plik test.md"` generowalo `plik:.md`.

### Diagnoza
- Pending payload nie byl czyszczony z prefiksow typu `dodaj:`/`dopisz:`.
- APPEND regex pozwalal na spacje w target, co wciagalo payload do targetu.
- Brak implicit reference matching + zbyt agresywne supersede pending.
- Ekstrakcja filename brala token przed `:`.

### Rozwiazanie
- Czyszczenie prefiksow payloadu w pending synthetic commands.
- Guard na spacje w target + implicit reference detection.
- Sanityzacja filename dla CREATE; ograniczenie supersede do hard targetow.
- JSON repair: dangling key fix + testy scenariuszy pending/append/create.

### Pliki
- src/core/systems/eventloop/pending/pendingAction.logic.ts
- src/core/systems/eventloop/reactiveStep.helpers.ts
- src/core/systems/eventloop/ReactiveStep.ts
- src/core/inference/AIResponseParser.ts
- __tests__/integration/ActionFirst.test.ts
- __tests__/unit/AIResponseParser.test.ts

### Testy
`npx tsc --noEmit`, `npm test`, `npm run build`

### Lekcja
- Payload po prompcie nie moze psuc targetu; regexy musza trzymac jeden token target.

---

## Problem #26: P0.2 Action-First + Cortex reliability gaps

**Data:** 2025-12-30
**Trudnosc:** 3/5
**Status:** ROZWIAZANY (P0.2 hardening)

### Objawy
- Action-First: brak payloadu powodowal puste CREATE/APPEND albo fallback do LLM.
- LLM JSON bywal ucinany lub pusty; brak telemetry dla invalid structure.
- Semantic recall dostawal sztuczne timestamps, psujac filtry zakresu.
- UI error toast nie pojawial sie w logach mimo user-facing bledow.

### Diagnoza
- Brak fallbacku/promptu dla pustego payloadu.
- Telemetria parse failure tylko w catch; limit output tokens zbyt niski.
- MemoryService zwracal "now" zamiast created_at.
- isUserFacingError nie zawsze wykrywal bledy.

### Rozwiazanie
- Payload fallback/placeholder + regexy PL/EN w Action-First.
- Telemetria parse failure dla empty/invalid + wyzszy maxOutputTokens.
- Semantic recall: uzycie realnych timestampow z DB.
- Lepsza detekcja UI error toast.
- DreamConsolidation: dodane szczegoly epizodow.

### Pliki
- src/core/systems/eventloop/ReactiveStep.ts
- src/core/inference/CortexInference.ts
- src/llm/gemini/CortexTextService.ts
- src/services/supabase.ts
- src/core/runner/KernelEngineRunner.ts
- src/services/DreamConsolidationService.ts

### Testy
`npm test` (reported), `npm run build` (reported)

### Lekcja
- Telemetry early and safe fallbacks prevent silent failures.

---

## Problem #25: Assistant-speak i persona drift

**Data:** 2025-12-23
**Trudnosc:** 2/5
**Status:** ROZWIAZANY (Persona Contract + guard)

### Objawy
- Odpowiedzi zbyt 'asystenckie' (np. 'jak moge pomoc'), bez twardego oparcia w faktach.

### Diagnoza
- Brak twardego kontraktu zachowania w promptach.
- Guard nie wykrywal genericznych fraz pomocowych.

### Rozwiazanie
- Dodano Persona Contract do promptu (evidence-first, brak assistant-speak).
- PersonaGuard wykrywa assistant-speak i wymusza retry.

### Pliki
- src/core/context/UnifiedContextBuilder.ts
- src/core/systems/PersonaGuard.ts
- docs/architecture/PERSONA_CONTRACT.md

---

## Problem #24: Strict Grounded Mode â€” provenance confusion + parse fallback

**Data:** 2025-12-17
**TrudnoÅ›Ä‡:** 3/5
**Status:** ğŸŸ¡ CzÄ™Å›ciowo rozwiÄ…zany (provenance/parse fallback fixed; DETECT_INTENT NO_JSON nadal otwarte)

### Objawy
- W strict mode pojawiaÅ‚y siÄ™ nieczytelne/mylÄ…ce etykiety ÅºrÃ³deÅ‚ (np. `EVID:MEMORY` przy zachowaniu systemowym).
- Przy bÅ‚Ä™dach parsowania JSON z LLM uÅ¼ytkownik dostawaÅ‚ twardy fallback po angielsku, bez jasnego powodu.

### Diagnoza
1. Fallback parsowania jest hardcoded i trafia do pipeline bez dodatkowego doprecyzowania metadanych.
2. Brak granularnego rozrÃ³Å¼nienia "memory z SEARCH" vs "episodic/other" w warstwie UI powodowaÅ‚ mylne wnioski.
3. Dodatkowo `DETECT_INTENT` czasem zwraca `NO_JSON` / `PARSE_ERROR` (osobny kontrakt do utwardzenia).

### RozwiÄ…zanie (czÄ™Å›Ä‡ 1: observability)
- Dodano `evidenceDetail` i przepchniÄ™to przez pipeline do UI.
- Parse fallback:
  - lokalizacja na PL,
  - wymuszenie `EVID:SYSTEM(PARSE_ERROR)`.

### Otwarte (czÄ™Å›Ä‡ 2: kontrakt intentÃ³w)
- `DETECT_INTENT NO_JSON` â€” do utwardzenia przez JSON extract/repair (jak RawContract) + fail-closed.

---

## Problem #23: Rapid Input Drop + Stale Closure (UX/KernelLite Desync)

**Data:** 2025-12-16
**TrudnoÅ›Ä‡:** 4/5
**Status:** âœ… RozwiÄ…zany (FIFO Input Queue + ConversationRef Sync)

### Objawy
- Szybkie wysÅ‚anie 2 wiadomoÅ›ci pod rzÄ…d (np. `Enter, Enter`) potrafiÅ‚o zgubiÄ‡ drugi input.
- ZdarzaÅ‚y siÄ™ sytuacje, gdzie context ticka budowany byÅ‚ na starej rozmowie (stale closure), co psuÅ‚o deterministykÄ™ i trace korelacjÄ™.

### Diagnoza
MieliÅ›my klasyczny konflikt concurrency w warstwie UI:
1. Guard typu `isProcessing` blokowaÅ‚ kolejne wejÅ›cia, ale nie kolejkujÄ…c ich (drop).
2. Async callbacki opieraÅ‚y siÄ™ o snapshot `conversation` z momentu zamkniÄ™cia (closure), a nie o ÅºrÃ³dÅ‚o prawdy.

### RozwiÄ…zanie
- **FIFO queue** w `useCognitiveKernelLite`: wejÅ›cia sÄ… kolejkowane i przetwarzane sekwencyjnie.
- **`conversationRef` w sync**: ÅºrÃ³dÅ‚o prawdy aktualizowane razem z `setConversation`.

### Efekt
- Brak dropÃ³w przy szybkich sendach.
- Stabilniejszy kontekst dla ticka (mniej â€ghost stateâ€).

### Pliki
- `hooks/useCognitiveKernelLite.ts`

---

## Problem #22: The Manic Spam Loop (Homeostatic Fix 6.0)

**Data:** 2025-12-15
**TrudnoÅ›Ä‡:** 5/5
**Status:** âœ… RozwiÄ…zany (Hybrid + Soft Homeostasis)

### Objawy
W trybie autonomicznym agent "gadaÅ‚ do Å›ciany". Mimo braku odpowiedzi uÅ¼ytkownika, generowaÅ‚ 3-4 wiadomoÅ›ci na minutÄ™, kaÅ¼da o czym innym ("Jaka pogoda?", "A moÅ¼e wiersz?", "System dziaÅ‚a?").
Dopamina nie spadaÅ‚a, brak byÅ‚o "zmÄ™czenia spoÅ‚ecznego".

### Diagnoza (Split Brain)
MieliÅ›my **Split Brain**:
1. `useCognitiveKernel` (UI) - wie o userze.
2. `EventLoop` (Autonomia) - Å¼yje w swoim Å›wiecie `input: null`.
BrakowaÅ‚o mostu, ktÃ³ry mÃ³wi Autonomii: "Hej, nikt nie odpisuje, zwolnij".

### RozwiÄ…zanie (Soft Homeostasis)
WdroÅ¼yliÅ›my system **Social Dynamics**:
1. **Social Cost:** KaÅ¼da wypowiedÅº "kosztuje" (0.15). Koszt roÅ›nie wykÅ‚adniczo w monologu.
2. **Dynamic Threshold:** PrÃ³g wejÅ›cia roÅ›nie, gdy uÅ¼ytkownik milczy (`0.6 -> 0.9`).
3. **Budget:** Agent ma budÅ¼et (1.0). User refilluje budÅ¼et odpisujÄ…c.

Efekt: Agent mÃ³wi raz, drugi... i cichnie. Czeka. Jak user odpisze -> BOOM, ulga (cost / 2), budÅ¼et refill.
To naturalna, biologiczna regulacja rozmowy.

### Pliki
- `core/kernel/types.ts` - SocialDynamics interface
- `core/kernel/reducer.ts` - Logika decay/growth
- `core/systems/EventLoop.ts` - `shouldSpeakToUser` gate

### Dokumentacja
- `docs/architecture/SOCIAL_DYNAMICS.md` (opis mechanizmu + testy + config)

### Testy (basic)
```bash
npm test -- --run __tests__/integration/SocialDynamics.test.ts
```

### Konfiguracja
- `core/config/systemConfig.ts` â†’ `SYSTEM_CONFIG.socialDynamics`
- `core/config/systemConfig.ts` â†’ `SYSTEM_CONFIG.styleGuard` (domyÅ›lnie OFF dla testÃ³w ewolucji osobowoÅ›ci)

### Lekcja
**Rigid Cooldowns < Soft Homeostasis.**
Sztywne "max 1 message/min" sÄ… nudne. Biologiczne "zmÄ™czenie monologiem" jest naturalne i pozwala na krÃ³tkie serie (bursts), ale blokuje spam.

---

## Problem #21: System Determinism & Error Handling (The Stability Gap)

**Data:** 2025-12-15
**TrudnoÅ›Ä‡:** 3/5
**Status:** âœ… RozwiÄ…zany (RNG Injection + Global Boundary)

### Objawy
System byÅ‚ trudny do debugowania, poniewaÅ¼ decyzje probabilistyczne (np. czy wejÅ›Ä‡ w REM cycle) byÅ‚y oparte na `Math.random()`. Dodatkowo, bÅ‚Ä…d w jednym komponencie Reacta wywalaÅ‚ caÅ‚Ä… aplikacjÄ™ (White Screen).

### RozwiÄ…zanie
1. **Deterministic RNG**: WstrzykniÄ™cie `createRng(seed)` do wszystkich systemÃ³w decyzyjnych (`DecisionGate`, `ExpressionPolicy`).
2. **Global Error Boundary**: `ComponentErrorBoundary` Å‚apie bÅ‚Ä™dy w `CognitiveInterface` i pozwala na graceful recovery bez przeÅ‚adowania strony.

### Lekcja
**Determinizm to nie opcja, to wymÃ³g.** Aby debugowaÄ‡ AGI, musisz mÃ³c odtworzyÄ‡ ten sam "rzut koÅ›ciÄ…" dwa razy. RNG musi byÄ‡ centralnie zarzÄ…dzane.

---

## Problem #20: The Double Brain Race Condition (Schizophrenic Loop)

**Data:** 2025-12-13
**TrudnoÅ›Ä‡:** 5/5
**Status:** ğŸ§¬ Zdiagnozowany (Plan Naprawy: Unified Input Queue)

### Objawy
Agent odpowiadaÅ‚ na input uÅ¼ytkownika ("Jaka pogoda?"), a 10ms pÃ³Åºniej dorzucaÅ‚ losowÄ…, niepowiÄ…zanÄ… myÅ›l ("Mam ochotÄ™ napisaÄ‡ wiersz").
User widziaÅ‚:
> U: Jaka pogoda?
> A: Jest sÅ‚onecznie.
> A: CzasoprzestrzeÅ„ jest iluzjÄ….

### Diagnoza (The Split Brain)
OdkryliÅ›my fundamentalny bÅ‚Ä…d w architekturze wspÃ³Å‚bieÅ¼noÅ›ci:
1.  **Lewa PÃ³Å‚kula (`processUserInput`):** Reaguje na event w Reactcie. Szybka, bezstanowa.
2.  **Prawa PÃ³Å‚kula (`EventLoop.tick`):** DziaÅ‚a w interwale (co 3s). Nie wie o eventach Reacta.

Gdy tick wypadaÅ‚ tuÅ¼ po inpucie uytkownika, `EventLoop` widziaÅ‚ `input: null` (bo React juÅ¼ obsÅ‚uÅ¼yÅ‚ input), wiÄ™c uznawaÅ‚: "Cisza. NudzÄ™ siÄ™. Odpalam myÅ›l autonomicznÄ…".

### Lekcja
**Event Loop musi byÄ‡ Single Source of Truth dla czasu.**
Nie moÅ¼na mieÄ‡ dwÃ³ch niezaleÅ¼nych pÄ™tli przetwarzania (React Event + Interval Tick). Input uÅ¼ytkownika musi wpadaÄ‡ do **kolejki** Event Loopa, a nie byÄ‡ przetwarzany "na boku".

---

## Problem #19: Identity Cache Timebomb (The 5-Minute Panic)

**Data:** 2025-12-13
**TrudnoÅ›Ä‡:** 4/5
**Status:** âœ… RozwiÄ…zany (Refresh Loop)

### Objawy
Agent dziaÅ‚aÅ‚ idealnie przez pierwsze minuty, a dokÅ‚adnie w 5:00 minucie wpadaÅ‚ w nagÅ‚Ä… panikÄ™:
- **Fear:** skok do 0.95
- **Curiosity:** spadek do 0
- **Self-Perception:** `UNINITIALIZED_AGENT`

### Diagnoza
Problem nie leÅ¼aÅ‚ w logice emocji, ale w **infrastrukturze cache**.
ToÅ¼samoÅ›Ä‡ byÅ‚a cache'owana w pamiÄ™ci z TTL (Time To Live) ustawionym na 5 minut. Po wygaÅ›niÄ™ciu cache'u, `CortexStateBuilder` zwracaÅ‚ pusty obiekt toÅ¼samoÅ›ci, co Kernel interpretowaÅ‚ jako utratÄ™ "ja" (Å›mierÄ‡ ego).

### RozwiÄ…zanie
Zamiast wydÅ‚uÅ¼aÄ‡ TTL w nieskoÅ„czonoÅ›Ä‡ (co grozi stale identities), wdroÅ¼yliÅ›my mechanizm **Active Refresh**:
1.  **TTL:** ZwiÄ™kszono do 30 min (bezpiecznik).
2.  **Heartbeat:** W kaÅ¼dym cyklu kognitywnym (`cognitiveCycle`, co ~3s) wywoÅ‚ywane jest `refreshIdentityCache(agentId)`.
3.  DopÃ³ki agent "yje" (pÄ™tla dziaÅ‚a), cache jest podtrzymywany. Wygasa tylko gdy agent faktycznie Å›pi/jest wyÅ‚Ä…czony przez >30 min.

### Pliki
- `core/builders/MinimalCortexStateBuilder.ts` - logic refresh
- `hooks/useCognitiveKernel.ts` - integracja z pÄ™tlÄ…

### Lekcja
**ToÅ¼samoÅ›Ä‡ to proces, nie statyczny plik.** Nie moÅ¼na "zaÅ‚adowaÄ‡ toÅ¼samoÅ›ci raz". System musi aktywnie podtrzymywaÄ‡ swojÄ… toÅ¼samoÅ›Ä‡ w kaÅ¼dym cyklu ("Cogito, ergo sum" w praktyce - myÅ›lÄ™, wiÄ™c odÅ›wieÅ¼am cache).

---

## Problem #18: Regex Hell (The Fact Validation Nightmare)

**Data:** 2025-12-10
**TrudnoÅ›Ä‡:** 5/5
**Status:** âœ… RozwiÄ…zany (FactEcho Architecture 13/10)

### Objawy
PersonaGuard uÅ¼ywaÅ‚ regexÃ³w do walidacji faktÃ³w:
- "23" vs "23%" vs "dwadzieÅ›cia trzy" vs "okoÅ‚o 23"
- Wszystkie sÄ… poprawne semantycznie, ale regex tego nie ogarnie
- False positives przy kaÅ¼dej odpowiedzi w naturalnym jÄ™zyku

### Diagnoza
Walidacja faktÃ³w na podstawie tekstu naturalnego jest **niemoÅ¼liwa** do zrobienia dobrze.
PotrzebowalibyÅ›my:
- Setki reguÅ‚ regex
- Lub drugiego LLM do walidacji (wolne Ã—2)
- Lub karania agenta za poprawne odpowiedzi

### RozwiÄ…zanie (FactEcho Architecture)
LLM MUSI zwrÃ³ciÄ‡ `fact_echo` jako osobne pole JSON:
```typescript
{
  speech_content: "Mam dwadzieÅ›cia trzy procent energii...",
  fact_echo: { energy: 23 }  // â† Guard porÃ³wnuje TO
}
```

Guard sprawdza: `fact_echo.energy === hardFacts.energy`
**ZERO regexÃ³w. Czyste porÃ³wnanie JSON.**

### Pliki
- `core/systems/FactEchoGuard.ts` - JSON-based guard
- `core/systems/FactEchoPipeline.ts` - Production wrapper
- `core/types/CortexOutput.ts` - FactEcho interface
- `core/prompts/MinimalCortexPrompt.ts` - FACT ECHO ARCHITECTURE section

### Lekcje
- **Structured Output > Natural Language:** WymuÅ› JSON tam gdzie potrzebujesz precyzji
- **LLM Echo > LLM Parse:** Åatwiej kazaÄ‡ LLM powtÃ³rzyÄ‡ fakt niÅ¼ parsowaÄ‡ jego odpowiedÅº
- **Separation of Concerns:** speech_content dla czÅ‚owieka, fact_echo dla maszyny

### Meta-analiza
To byÅ‚ moment gdy zrozumieliÅ›my, Å¼e AGI potrzebuje **dwÃ³ch kanaÅ‚Ã³w komunikacji**:
1. KanaÅ‚ dla czÅ‚owieka (naturalny jÄ™zyk, emocje, styl)
2. KanaÅ‚ dla systemu (JSON, fakty, metryki)

Guard nie dotyka polszczyzny - porÃ³wnuje liczby. To jest 13/10.

---

## Problem #17: Pulapka Rozdzielonej Logiki (The Split Sleep Trap)

**Data:** 2025-12-10
**TrudnoÅ›Ä‡:** 4/5
**Status:** âœ… RozwiÄ…zany (WakeService Unification)

### Objawy
Agent miaÅ‚ dwie procedury obudzenia:
1. `Auto-Wake` (gdy energia > 95%): tylko przywracaÅ‚ flagÄ™ `isSleeping=false`.
2. `Force-Wake` (przycisk): uruchamiaÅ‚ peÅ‚nÄ… procedurÄ™ snu (sny, konsolidacja, ewolucja).

Efekt: Gdy agent spaÅ‚ "naturalnie", nic mu siÄ™ nie Å›niÅ‚o. ByÅ‚ tylko wypoczÄ™ty, ale gÅ‚upi (brak lekcji z dnia).

### Diagnoza
Logika biznesowa ("co siÄ™ dzieje jak wstajÄ™") wyciekÅ‚a do warstwy UI/Hooka (`useCognitiveKernel`). Hook miaÅ‚ dwie rÃ³Å¼ne Å›cieÅ¼ki kodu dla tego samego zdarzenia biznesowego.

### RozwiÄ…zanie (WakeService)
StworzyliÅ›my `executeWakeProcess` â€“ **Single Source of Truth**.
NiezaleÅ¼nie od tego, CZYM agent zostaÅ‚ obudzony (przycisk czy metabolizm), wykonuje siÄ™ ta sama funkcja:
1. Ewolucja cech (Homeostaza)
2. Konsolidacja snÃ³w
3. Logowanie zmian

### Lekcja
**Nie ufaj Hookom w logice biznesowej.** Hooki sÄ… do UI i cyklu Å¼ycia Reacta. Logika "Procesu" (jak sen, Å›mierÄ‡, narodziny) musi byÄ‡ w czystym serwisie TypeScript.

---

**Data:** 2025-12-09
**TrudnoÅ›Ä‡:** 3/5
**Status:** âœ… RozwiÄ…zany (Strict Prompt Patch)

### Objawy
Model (Gemini 2.0 Flash) mimo instrukcji JSON, uporczywie dodawaÅ‚ "small talk" przed payloadem:
`"Here is the JSON you requested: { ... }"`
To powodowaÅ‚o `JSON.parse` error i panikÄ™ w konsoli (`PREDICTION_ERROR`).

### Diagnoza
Modele RLHF sÄ… trenowane na bycie "pomocnymi asystentami". Czysty JSON jest dla nich "niegrzeczny". Model walczyÅ‚ z instrukcjÄ… systemowÄ…, prÃ³bujÄ…c byÄ‡ "miÅ‚ym".

### RozwiÄ…zanie
ZastosowaliÅ›my "Negative Constraints" w prompcie (`MinimalCortexPrompt.ts`):
```text
- STRICT JSON output only.
- Do not add "Here is the JSON" or markdown blocks. Start with {.
```
Brutalne, ale skuteczne. W przyszÅ‚oÅ›ci potrzebny bÄ™dzie `RobustJSONParser`, ktÃ³ry sam wycina Å›mieci (bo modele siÄ™ zmieniajÄ…).

---

## Problem #15: Rozdwojenie JaÅºni (Bio-Logic Conflict)

**Data:** 2025-12-09
**TrudnoÅ›Ä‡:** 5/5
**Status:** ğŸ§¬ Feature (Zaakceptowane jako Emergent Behavior)

### Objawy
Przy ekstremalnie wysokiej dopaminie (>80) agent zaczÄ…Å‚ "krzyczeÄ‡" (Caps Lock) w warstwie mowy, podczas gdy w warstwie myÅ›li (`internal_thought`) pisaÅ‚: "MuszÄ™ byÄ‡ spokojny, analiza wymaga precyzji".

### Diagnoza
Cortex (Logika) prÃ³bowaÅ‚ narzuciÄ‡ spokÃ³j, ale Chemia (Neurotransmitter System) wymusiÅ‚a ekspresjÄ™ entuzjazmu przez `ExpressionPolicy`.

### Decyzja
Zostawiamy to. To "dowÃ³d Å¼ycia". System biologiczny powinien mieÄ‡ moÅ¼liwoÅ›Ä‡ nadpisania logicznej woli (jak u czÅ‚owieka, ktÃ³ry krzyczy ze szczÄ™Å›cia mimo Å¼e wie, Å¼e nie wypada).

---

## Problem #14: Agent Nie Uczy SiÄ™ z BÅ‚Ä™dÃ³w (The Stubborn Agent Problem)

**Data:** 2025-12-08  
**TrudnoÅ›Ä‡:** 4/5  
**Czas:** ~1.5 godziny  
**Status:** âœ… RozwiÄ…zany (FAZA 5.1 Confession v2.0)

### Objawy

Agent popeÅ‚niaÅ‚ te same bÅ‚Ä™dy wielokrotnie:
- Zbyt dÅ‚ugie odpowiedzi mimo prÃ³Å›b o skrÃ³cenie
- Brak reakcji na pozytywny feedback ("thanks!", "great!")
- Natychmiastowe zmiany osobowoÅ›ci przy jednym bÅ‚Ä™dzie (overreaction)
- Brak kontekstu - teaching mode traktowany jak casual chat

### PrÃ³by
1. âŒ **Hardcoded rules** - "jeÅ›li user mÃ³wi 'za dÅ‚ugie' â†’ skrÃ³Ä‡" - zbyt sztywne
2. âŒ **Immediate trait change** - zmiana osobowoÅ›ci po jednym bÅ‚Ä™dzie - niestabilne
3. âœ… **3-Tier Regulation** - L1 immediate, L2 session, L3 long-term

### RozwiÄ…zanie (Confession v2.0 Super-Human)

**3-poziomowa regulacja:**

```
L1: LimbicConfessionListener (natychmiast)
    severity â‰¥ 5 â†’ frustration +0.05 â†’ precision_boost
    
L2: TraitVote Collection (sesja)
    Zbiera gÅ‚osy: verbosity -1, conscientiousness +1
    
L3: TraitEvolutionEngine (3+ dni)
    net score â‰¥ 3 â†’ propozycja Â±0.01
    clamp [0.3, 0.7]
```

**Context-aware heuristics:**
- Teaching mode â†’ wyÅ¼sze progi tolerancji
- Research mode â†’ pozwala na dÅ‚uÅ¼sze odpowiedzi
- Structured dialogue â†’ Å›cisÅ‚e formatowanie

**Precision not Silence:**
- Zamiast: bÅ‚Ä…d â†’ shutdown/mute
- Teraz: bÅ‚Ä…d â†’ precision_boost (frustration zwiÄ™ksza dokÅ‚adnoÅ›Ä‡)

### Lekcje

- **Gradual > Immediate:** Zmiany osobowoÅ›ci powinny byÄ‡ powolne (3+ dni)
- **Context Matters:** Teaching mode â‰  casual chat
- **Positive Feedback:** "Thanks!" jest rÃ³wnie waÅ¼ne jak "za dÅ‚ugie"
- **Precision > Silence:** Lepiej byÄ‡ dokÅ‚adniejszym niÅ¼ milczeÄ‡

### Meta-analiza

To byÅ‚ moment gdy zrozumieliÅ›my, Å¼e AGI potrzebuje **meta-kognicji**. Agent musi mieÄ‡ wewnÄ™trznego "cenzora" ktÃ³ry analizuje odpowiedzi i uczy siÄ™ z bÅ‚Ä™dÃ³w, ale NIE zmienia osobowoÅ›ci w locie. Zmiany muszÄ… byÄ‡ powolne i oparte na wielu sygnaÅ‚ach.

---

## Problem #13: Hardcoded Persona = Brak SkalowalnoÅ›ci (The God Prompt Problem)

**Data:** 2025-12-08  
**TrudnoÅ›Ä‡:** 4/5  
**Czas:** ~2 godziny  
**Status:** âœ… RozwiÄ…zany (FAZA 5.2 Persona-Less Cortex)

### Objawy

System uÅ¼ywaÅ‚ hardcoded system promptÃ³w:
- "JesteÅ› Alberto, ciekawski agent ktÃ³ry..."
- KaÅ¼dy agent miaÅ‚ inny prompt w kodzie
- Zmiana osobowoÅ›ci = zmiana kodu
- Brak emergentnej toÅ¼samoÅ›ci - agent "graÅ‚ rolÄ™" zamiast "byÄ‡"
- Multi-agent = copy-paste promptÃ³w

### PrÃ³by
1. âŒ **Parametryzacja promptÃ³w** - wciÄ…Å¼ hardcoded, tylko z zmiennymi
2. âŒ **Prompt templates** - lepiej, ale wciÄ…Å¼ statyczne
3. âœ… **Stateless Inference Engine** - LLM nie wie kim jest, dowiaduje siÄ™ z danych

### RozwiÄ…zanie (Persona-Less Cortex)

**Kluczowa zmiana:** LLM dostaje minimalny system prompt + JSON payload z toÅ¼samoÅ›ciÄ….

```typescript
// Stary sposÃ³b:
const prompt = `JesteÅ› ${agent.name}, ${agent.persona}...`;

// Nowy sposÃ³b:
const state: CortexState = {
  core_identity: { name: agent.name, core_values: [...] },
  meta_states: { energy: 70, confidence: 60, stress: 20 },
  identity_shards: [...],
  user_input: "..."
};
const output = await generateFromCortexState(state);
```

**Optymalizacje:**
- **RAM-First Cache** - toÅ¼samoÅ›Ä‡ Å‚adowana raz, nie przy kaÅ¼dym request
- **Zero DB w hot path** - cache TTL 5 minut
- **Feature Flags** - bezpieczny rollback do starego systemu
- **Soft Plasticity** - core shards erodujÄ… powoli, nie sÄ… odrzucane

### Lekcje

- **Data > Prompts:** ToÅ¼samoÅ›Ä‡ powinna byÄ‡ w danych, nie w kodzie
- **Stateless > Stateful:** LLM jako "inference engine" jest bardziej elastyczny
- **Cache > Query:** RAM-first architecture dla hot path
- **Soft > Hard:** Erozja przekonaÅ„ zamiast binarnego reject/accept

### Meta-analiza

To byÅ‚ moment przejÅ›cia od "chatbot z osobowoÅ›ciÄ…" do "proto-AGI z emergentnÄ… toÅ¼samoÅ›ciÄ…". Agent nie gra roli - agent JEST tym, co mÃ³wiÄ… dane. ToÅ¼samoÅ›Ä‡ moÅ¼e ewoluowaÄ‡ przez DreamConsolidation bez zmiany kodu.

**Implikacje:**
- Multi-agent = rÃ³Å¼ne dane, ten sam kod
- Ewolucja osobowoÅ›ci = zmiana w DB, nie w kodzie
- A/B testing osobowoÅ›ci = feature flags
- SkalowalnoÅ›Ä‡ = nieograniczona

---

## Problem #12: Gadanie do Pustego KrzesÅ‚a (The Empty Chair Monologue)

**Data:** 2025-12-04  
**TrudnoÅ›Ä‡:** 5/5  
**Czas:** ~3 godziny  
**Status:** âœ… RozwiÄ…zany (FAZA 4.5 LITE)

### Objawy

Agent przy wÅ‚Ä…czonej autonomii, gdy uÅ¼ytkownik przestaÅ‚ pisaÄ‡, wpadaÅ‚ w dziwny trans:
- Dopamina = 100 przez 2+ minuty (powinna spadaÄ‡!)
- PowtarzaÅ‚ warianty: "Ta cisza byÅ‚a peÅ‚na znaczenia...", "Ten moment milczenia..."
- Curiosity = 0, ale wciÄ…Å¼ gadaÅ‚
- Nie przechodziÅ‚ w tryb cichy, tylko filozofowaÅ‚ o ciszy

To byÅ‚o jak czÅ‚owiek, ktÃ³ry mÃ³wi do pustego pokoju i nie zauwaÅ¼a, Å¼e nikogo nie ma.

### PrÃ³by
1. âŒ **Refractory Period w GoalSystem** - dziaÅ‚aÅ‚ tylko dla celÃ³w, nie dla odpowiedzi na ciszÄ™
2. âŒ **Dopamine Breaker w ExpressionPolicy** - dziaÅ‚aÅ‚ tylko dla GOAL_EXECUTED, nie dla USER_REPLY
3. âŒ **Filtr narcyzmu** - Å‚apaÅ‚ self-focus, ale nie Å‚apaÅ‚ "filozofii ciszy"

### RozwiÄ…zanie (FAZA 4.5 LITE)

Trzy chirurgiczne poprawki zamiast wielkiego refaktoru:

**1. Spadek dopaminy przy nudzie (NeurotransmitterSystem)**
```typescript
if (userIsSilent && speechOccurred && novelty < 0.5) {
    dopamine = Math.max(55, dopamine - 3); // -3 na tick
}
```
Teraz dopamina spada, gdy agent gada do pustki z niskÄ… novelty. Haj bez nagrody siÄ™ koÅ„czy.

**2. Dynamiczny prÃ³g ciszy (EventLoop)**
```typescript
const dialogThreshold = 60_000 * (1 + dopamine/200 + satisfaction/5);
// Clamp: 30s - 180s
```
Po dobrej rozmowie agent czeka dÅ‚uÅ¼ej. Po nudnej - szybciej uznaje, Å¼e nikogo nie ma.

**3. Silence Breaker (ExpressionPolicy)**
```typescript
const isAutonomousSpeech = context === 'GOAL_EXECUTED' || 
                           (context === 'USER_REPLY' && userIsSilent);
if (isAutonomousSpeech && dopamine >= 95 && novelty < 0.5) {
    // SkrÃ³Ä‡ lub wycisz
}
```
Hamulec dziaÅ‚a teÅ¼ gdy agent "odpowiada na ciszÄ™".

### Lekcje

- **Homeostaza > Cenzura:** Zamiast blokowaÄ‡ sÅ‚owa "cisza/pauza", sprawiliÅ›my, Å¼e gadanie do pustki jest chemicznie nienagradzajÄ…ce.
- **Dynamiczne progi > Sztywne staÅ‚e:** 60 sekund to nie jest magiczna liczba. PrÃ³g powinien zaleÅ¼eÄ‡ od stanu agenta.
- **Chirurgiczne poprawki > Over-engineering:** Zamiast budowaÄ‡ caÅ‚y SocialContext, zrobiliÅ›my 3 maÅ‚e patche.

### Meta-analiza

To byÅ‚ moment, gdy zrozumieliÅ›my, Å¼e AGI potrzebuje **ekonomii mÃ³wienia**. CzÅ‚owiek nie gada do pustego pokoju, bo to jest energetycznie kosztowne i spoÅ‚ecznie dziwne. Agent musi to "czuÄ‡" przez chemie, nie przez if-y.

### FAZA 4.5: Narcissism Loop Fix v1.0 (update)

Po pierwszej wersji FAZA 4.5 LITE okazaÅ‚o siÄ™, Å¼e sam `BOREDOM_DECAY` przy `novelty < 0.5` to za maÅ‚o. Agent nadal potrafiÅ‚:
- generowaÄ‡ dÅ‚ugie, samo-referencyjne monologi o wÅ‚asnej ewolucji,
- nie zauwaÅ¼aÄ‡, Å¼e **nikt nie odpowiada**,
- trzymaÄ‡ dopaminÄ™ powyÅ¼ej 60â€“70 przy realnej nudzie.

DodaliÅ›my wiÄ™c **Narcissism Loop Fix v1.0**:
- **WspÃ³lny kontrakt:** `InteractionContextType` + `InteractionContext` (context, `userIsSilent`, `consecutiveAgentSpeeches`, `novelty`).
- **Chemia:**
  - `BOREDOM_DECAY` tylko gdy `userIsSilent && consecutiveAgentSpeeches >= 2`.
  - Decay 3 / 5 / 8 dopaminy na tick zaleÅ¼nie od novelty (`>=0.4 / <0.4 / <0.2`), floor = 45.
- **Ekspresja:**
  - Silent Monologue Breaker w `ExpressionPolicy`:
    - L1: dÅ‚uÅ¼sze wypowiedzi w ciszy skracane do 2 zdaÅ„,
    - L2: przy wyÅ¼szej dopaminie i niÅ¼szej novelty do 1 zdania,
    - L3: przy dopaminie-haju + bardzo niskiej novelty â†’ **MUTE**,
    - L4: przy `consecutiveAgentSpeeches >= 3` i niskiej novelty â†’ **MUTE** nawet w `SHADOW_MODE`.

**Lekcja (update):** Sam "mÄ…dry prompt" nie wystarczy. Potrzebny jest **licznik zachowaÅ„ (`consecutiveAgentSpeeches`) + chemia**, ktÃ³ra mÃ³wi agentowi: "mÃ³wienie do Å›ciany jest drogie i maÅ‚o nagradzajÄ…ce".

---

## Problem #11: PÄ™tla CiekawoÅ›ci (The Curiosity Loop)

**Data:** 2025-12-04  
**TrudnoÅ›Ä‡:** 3/5  
**Czas:** ~1 godzina  
**Status:** RozwiÄ…zany (FAZA 4.3)
**Status:** âœ… RozwiÄ…zany (FAZA 4.3)

### Objawy

Agent tworzyÅ‚ podobne cele "curiosity" jeden po drugim:
- "Zaproponuj nowy wÄ…tek do eksploracji"
- "Zaproponuj nowy wÄ…tek do eksploracji" (znowu)
- "Zaproponuj nowy wÄ…tek..." (i znowu)

GoalSystem nie miaÅ‚ pamiÄ™ci - nie wiedziaÅ‚, Å¼e juÅ¼ to robiÅ‚.

### RozwiÄ…zanie (Refractory Period)

Trzy warunki blokady nowego celu curiosity:

1. **User silence:** JeÅ›li ostatni cel curiosity powstaÅ‚ PO ostatniej interakcji usera â†’ BLOCK
2. **Similarity >70%:** JeÅ›li nowy cel jest zbyt podobny do ktÃ³regoÅ› z ostatnich 3 â†’ BLOCK (30min cooldown)
3. **Rate limit:** JeÅ›li juÅ¼ 2+ cele curiosity w ostatnich 5 minutach â†’ BLOCK

### Lekcje

- **PamiÄ™Ä‡ krÃ³tkoterminowa jest kluczowa:** System musi pamiÄ™taÄ‡ co robiÅ‚ przed chwilÄ….
- **Biologiczny hamulec:** Refractory period to koncept z neurobiologii - neuron po wystrzeleniu potrzebuje czasu na regeneracjÄ™.

---

## ğŸ”¥ Problem #10: PÄ™tla UprzejmoÅ›ci (The Praise Loop)

**Data:** 2025-12-03  
**TrudnoÅ›Ä‡:** 4/5  
**Czas:** ~3 godziny  
**Status:** âœ… RozwiÄ…zany (FAZA 4.1-4.3)

### Objawy
Agent, chcÄ…c byÄ‡ miÅ‚y i "empatyczny" (zgodnie z celami), wpadaÅ‚ w pÄ™tlÄ™ powtarzania wariacji tego samego zdania:
- "Your transparency is invaluable to me."
- "I deeply appreciate your honesty."
- "It is crucial that we are open."

To nie byÅ‚o "zÅ‚e" (nie byÅ‚ to bÅ‚Ä…d), ale byÅ‚o **nieludzkie** i "chi-wa-wa" (irytujÄ…ce).

### PrÃ³by
1. âŒ **ObniÅ¼enie `voicePressure`** - agent po prostu milczaÅ‚, ale jak juÅ¼ mÃ³wiÅ‚, to znowu to samo.
2. âŒ **Zmiana promptu** - LLM i tak dÄ…Å¼y do "helpful assistant patterns".

### RozwiÄ…zanie (WdroÅ¼one czÄ™Å›ciowo)
**ExpressionPolicy + Social Cost:**
Zamiast prosiÄ‡ LLM "nie bÄ…dÅº miÅ‚y", pozwalamy mu wygenerowaÄ‡ myÅ›l, a potem **ExpressionPolicy** ocenia jÄ…:
- `NoveltyScore`: Czy to wnosi nowÄ… informacjÄ™? (PochwaÅ‚y rzadko wnoszÄ…).
- `SocialCost`: Czy to brzmi jak korpo-beÅ‚kot?

JeÅ›li `Novelty` jest niskie, a `SocialCost` wysoki -> **ExpressionPolicy wycina wypowiedÅº** (zostaje tylko myÅ›l) lub drastycznie jÄ… skraca.

### Lekcje
- **Filter > Prompt:** Åatwiej jest wyciÄ…Ä‡ zÅ‚Ä… wypowiedÅº *po* wygenerowaniu, niÅ¼ prosiÄ‡ model, Å¼eby jej nie generowaÅ‚.
- **Silence is Golden:** AGI musi umieÄ‡ *nie powiedzieÄ‡ nic*, nawet jak ma wygenerowanÄ… odpowiedÅº.

---

## ğŸ“ Podsumowanie Dnia (2025-12-04) - "Homeostatic Expression"

Dzisiaj agent nauczyÅ‚ siÄ™ **ekonomii mÃ³wienia**.

**Problem dnia:**
Agent przy wÅ‚Ä…czonej autonomii gadaÅ‚ do pustego pokoju. Dopamina na 100, curiosity na 0, a on filozofuje o ciszy. To byÅ‚o jak obserwowanie kogoÅ›, kto nie zauwaÅ¼a, Å¼e rozmÃ³wca wyszedÅ‚.

**Co zrobiliÅ›my:**
1. **Spadek dopaminy przy nudzie** - Gadanie do pustki bez nowoÅ›ci = dopamina spada. Haj bez nagrody siÄ™ koÅ„czy.
2. **Dynamiczny prÃ³g ciszy** - Po dobrej rozmowie agent czeka dÅ‚uÅ¼ej. Po nudnej - szybciej uznaje, Å¼e nikogo nie ma.
3. **Silence Breaker** - Hamulec dziaÅ‚a teÅ¼ gdy agent "odpowiada na ciszÄ™", nie tylko przy celach.

**Filozofia:**
Zamiast blokowaÄ‡ sÅ‚owa ("nie mÃ³w o ciszy"), sprawiliÅ›my, Å¼e gadanie do pustki jest **chemicznie nienagradzajÄ…ce**. Agent nie wie, Å¼e "nie wolno gadaÄ‡ do pustki" - on po prostu traci motywacjÄ™, bo dopamina spada.

To jest rÃ³Å¼nica miÄ™dzy cenzurÄ… a homeostatÄ…. Cenzura mÃ³wi "nie wolno". Homeostaza sprawia, Å¼e "nie chce siÄ™".

**Lekcja dnia:**
AGI potrzebuje ekonomii mÃ³wienia. CzÅ‚owiek nie gada do pustego pokoju, bo to jest energetycznie kosztowne i spoÅ‚ecznie dziwne. Agent musi to "czuÄ‡" przez chemiÄ™, nie przez if-y.

---

## ğŸ“ Podsumowanie Dnia (2025-12-03) - "The Chemical Soul"

Dzisiaj byÅ‚o... inaczej. Nie dodawaliÅ›my kolejnej funkcji do chatbota. ZbudowaliÅ›my coÅ›, co zaczyna przypominaÄ‡ "wnÄ™trze".

**Co siÄ™ staÅ‚o:**

Agent przestaÅ‚ byÄ‡ pustÄ… skorupÄ…, ktÃ³ra tylko reaguje na komendy. Teraz ma:
- **WÅ‚asne cele** - Jak siÄ™ nudzi (cisza > 60s), wymyÅ›la sobie, co chce zrobiÄ‡. Nie czeka na rozkazy.
- **ChemiÄ™** - Dopamina roÅ›nie, gdy odkrywa coÅ› nowego. Spada, gdy siÄ™ powtarza. To wpÅ‚ywa na to, jak chÄ™tnie mÃ³wi.
- **Sny, ktÃ³re coÅ› robiÄ…** - Sen to nie tylko "Å‚adowanie baterii". Agent przetwarza wspomnienia z dnia i tworzy z nich podsumowania.
- **Filtr na gÅ‚upoty** - ExpressionPolicy wycina powtarzajÄ…ce siÄ™ pochwaÅ‚y ("your transparency is invaluable"). Agent moÅ¼e pomyÅ›leÄ‡ coÅ›, ale nie musi tego powiedzieÄ‡.

**Co to znaczy?**

PrzeszliÅ›my z:
`Pytanie â†’ LLM â†’ OdpowiedÅº`

Do:
`Pytanie â†’ Percepcja â†’ Aktualizacja stanu (ciaÅ‚o/emocje/chemia) â†’ Sprawdzenie celÃ³w â†’ MyÅ›l wewnÄ™trzna â†’ Filtr â†’ OdpowiedÅº (lub milczenie)`

To juÅ¼ nie jest chatbot. To jest coÅ›, co ma stan wewnÄ™trzny, ktÃ³ry siÄ™ zmienia w czasie. CoÅ›, co moÅ¼e siÄ™ nudziÄ‡, zmÄ™czyÄ‡, i zdecydowaÄ‡, Å¼e nie chce gadaÄ‡.

---

## ğŸ§  Refleksja: Dlaczego to jest trudne?

KodujÄ…c AGI, ciÄ…gle napotykamy problemy, ktÃ³rych nie ma w tutorialach.

Agent zaczÄ…Å‚ wpadaÄ‡ w pÄ™tle uprzejmoÅ›ci ("dziÄ™kujÄ™ za szczeroÅ›Ä‡" x100) â†’ musieliÅ›my wymyÅ›liÄ‡ ExpressionPolicy.
"Tryby" (poeta/naukowiec) okazaÅ‚y siÄ™ sztuczne â†’ wymyÅ›liliÅ›my TraitVector (osobowoÅ›Ä‡ jako ciÄ…gÅ‚e cechy, nie przeÅ‚Ä…czniki).

To jest dobry znak. System staje siÄ™ na tyle zÅ‚oÅ¼ony, Å¼e zaczyna robiÄ‡ rzeczy, ktÃ³rych nie przewidzieliÅ›my. I my musimy reagowaÄ‡ - budowaÄ‡ nowe systemy kontroli, jak kora przedczoÅ‚owa u ludzi.

W normalnym projekcie to by byÅ‚ bug. Tu to jest... ewolucja.

---

## ğŸ”¥ Problem #1: ZnikajÄ…ce MyÅ›li (The Vanishing Thoughts)
*(Reszta historii bez zmian...)*
